{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "_piESxLUlauJ"
      },
      "outputs": [],
      "source": [
        "model_name = \"roberta-base\"\n",
        "\n",
        "plodv2_filtered_data = load_dataset(\"surrey-nlp/PLODv2-filtered\")\n",
        "sample_fraction = 0.25\n",
        "num_train_sample = int(len(plodv2_filtered_data['train']) * sample_fraction)\n",
        "num_val_sample = int(len(plodv2_filtered_data['validation']) * sample_fraction)\n",
        "train_indices = random.sample(range(len(plodv2_filtered_data['train'])), num_train_sample)\n",
        "val_indices = random.sample(range(len(plodv2_filtered_data['validation'])), num_val_sample)\n",
        "plodv2_filtered_train_data = plodv2_filtered_data['train'].select(train_indices)\n",
        "plodv2_filtered_val_data = plodv2_filtered_data['validation'].select(val_indices)\n",
        "ds['train'] = concatenate_datasets([ds['train'], plodv2_filtered_train_data])\n",
        "ds['validation'] = concatenate_datasets([ds['validation'], plodv2_filtered_val_data])\n",
        "\n",
        "train_df = pd.DataFrame(ds['train'])\n",
        "val_df = pd.DataFrame(ds['validation'])\n",
        "test_df = pd.DataFrame(ds['test'])\n",
        "\n",
        "train_df['tokens'] = train_df['tokens'].apply(tuple)\n",
        "train_df['pos_tags'] = train_df['pos_tags'].apply(tuple)\n",
        "train_df['ner_tags'] = train_df['ner_tags'].apply(tuple)\n",
        "train_df.drop_duplicates(subset=['tokens', 'pos_tags', 'ner_tags'], inplace=True)\n",
        "train_df['tokens'] = train_df['tokens'].apply(list)\n",
        "train_df['pos_tags'] = train_df['pos_tags'].apply(list)\n",
        "train_df['ner_tags'] = train_df['ner_tags'].apply(list)\n",
        "\n",
        "train_dataset = Dataset.from_pandas(train_df)\n",
        "test_dataset = Dataset.from_pandas(test_df)\n",
        "validation_dataset = Dataset.from_pandas(val_df)\n",
        "\n",
        "dataset_dict = DatasetDict({\n",
        "    \"train\": train_dataset,\n",
        "    \"test\": test_dataset,\n",
        "    \"validation\": validation_dataset\n",
        "})\n",
        "\n",
        "\n",
        "additional_dataset = dataset_dict\n",
        "\n",
        "tokenizer = RobertaTokenizerFast.from_pretrained(\"roberta-base\",add_prefix_space=True)\n",
        "label_all_tokens = True\n",
        "def tokenize_and_align_labels(examples):\n",
        "    tokenized_inputs = tokenizer(examples[\"tokens\"], truncation=True, is_split_into_words=True)\n",
        "\n",
        "    labels = []\n",
        "    for i, label in enumerate(examples[f\"ner_tags\"]):\n",
        "        word_ids = tokenized_inputs.word_ids(batch_index=i)\n",
        "        previous_word_idx = None\n",
        "        label_ids = []\n",
        "        for word_idx in word_ids:\n",
        "            # Special tokens have a word id that is None. We set the label to -100 so they are automatically\n",
        "            if word_idx is None:\n",
        "                label_ids.append(-100)\n",
        "            # We set the label for the first token of each word.\n",
        "            elif word_idx != previous_word_idx:\n",
        "                label_ids.append(label[word_idx])\n",
        "            else:\n",
        "                label_ids.append(label[word_idx] if label_all_tokens else -100)\n",
        "            previous_word_idx = word_idx\n",
        "\n",
        "        labels.append(label_ids)\n",
        "\n",
        "    tokenized_inputs[\"labels\"] = labels\n",
        "    return tokenized_inputs\n",
        "\n",
        "tokenized_datasets = additional_dataset.map(tokenize_and_align_labels, batched=True)\n",
        "model = RobertaForTokenClassification.from_pretrained(\"roberta-base\", num_labels=len(label_list))\n",
        "args = TrainingArguments(\n",
        "    model_name,\n",
        "    eval_strategy= \"epoch\",\n",
        "    learning_rate=2e-5,\n",
        "    per_device_train_batch_size=16,\n",
        "    per_device_eval_batch_size=16,\n",
        "    num_train_epochs=3,\n",
        "    weight_decay=0.01,\n",
        "    logging_strategy=\"steps\",\n",
        "    logging_steps=10,\n",
        "    optim=\"adafactor\",\n",
        "    lr_scheduler_type=\"constant\",\n",
        ")\n",
        "data_collator = DataCollatorForTokenClassification(tokenizer)\n",
        "def compute_metrics(p):\n",
        "    predictions, labels = p\n",
        "    predictions = np.argmax(predictions, axis=2)\n",
        "\n",
        "    # Remove ignored index (special tokens)\n",
        "    true_predictions = [\n",
        "        [label_list[p] for (p, l) in zip(prediction, label) if l != -100]\n",
        "        for prediction, label in zip(predictions, labels)\n",
        "    ]\n",
        "    true_labels = [\n",
        "        [label_list[l] for (p, l) in zip(prediction, label) if l != -100]\n",
        "        for prediction, label in zip(predictions, labels)\n",
        "    ]\n",
        "\n",
        "    results = metric.compute(predictions=true_predictions, references=true_labels)\n",
        "    return {\n",
        "        \"precision\": results[\"overall_precision\"],\n",
        "        \"recall\": results[\"overall_recall\"],\n",
        "        \"f1\": results[\"overall_f1\"],\n",
        "        \"accuracy\": results[\"overall_accuracy\"],\n",
        "    }\n",
        "\n",
        "trainer = Trainer(\n",
        "    model,\n",
        "    args,\n",
        "    train_dataset=tokenized_datasets[\"train\"],\n",
        "    eval_dataset=tokenized_datasets[\"validation\"],\n",
        "    data_collator=data_collator,\n",
        "    processing_class=tokenizer,\n",
        "    compute_metrics=compute_metrics\n",
        ")\n",
        "\n",
        "trainer.train()\n",
        "trainer.evaluate()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "cwU_cdxXyD2R"
      },
      "outputs": [],
      "source": [
        "predictions, labels, _ = trainer.predict(tokenized_datasets[\"test\"])\n",
        "predictions = np.argmax(predictions, axis=2)\n",
        "\n",
        "# Remove ignored index (special tokens)\n",
        "true_predictions = [\n",
        "    [label_list[p] for (p, l) in zip(prediction, label) if l != -100]\n",
        "    for prediction, label in zip(predictions, labels)\n",
        "]\n",
        "true_labels = [\n",
        "    [label_list[l] for (p, l) in zip(prediction, label) if l != -100]\n",
        "    for prediction, label in zip(predictions, labels)\n",
        "]\n",
        "\n",
        "results = metric.compute(predictions=true_predictions, references=true_labels)\n",
        "print(results)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Class wise bar chart\n",
        "labels = [key for key in results if isinstance(results[key], dict)]  # e.g., ['AC', 'LF']\n",
        "precision = [results[label]['precision'] for label in labels]\n",
        "recall = [results[label]['recall'] for label in labels]\n",
        "f1 = [results[label]['f1'] for label in labels]\n",
        "\n",
        "x = range(len(labels))\n",
        "width = 0.2\n",
        "\n",
        "plt.figure(figsize=(8, 6))\n",
        "plt.bar([p - width for p in x], precision, width, label='Precision')\n",
        "plt.bar(x, recall, width, label='Recall')\n",
        "plt.bar([p + width for p in x], f1, width, label='F1 Score')\n",
        "\n",
        "plt.xticks(x, labels)\n",
        "plt.ylim(0, 1)\n",
        "plt.ylabel('Score')\n",
        "plt.title('Token-level Metrics by Class')\n",
        "plt.legend()\n",
        "plt.grid(True, axis='y')\n",
        "plt.tight_layout()\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "from sklearn.metrics import confusion_matrix\n",
        "import seaborn as sns\n",
        "\n",
        "flat_true = [item for sublist in true_labels for item in sublist]\n",
        "flat_pred = [item for sublist in true_predictions for item in sublist]\n",
        "labels = sorted(set(flat_true + flat_pred))\n",
        "\n",
        "cm = confusion_matrix(flat_true, flat_pred, labels=labels)\n",
        "\n",
        "plt.figure(figsize=(8, 6))\n",
        "sns.heatmap(cm, annot=True, fmt='d', cmap='Blues', xticklabels=labels, yticklabels=labels)\n",
        "plt.title('Confusion Matrix for PLOD-CW-25 + 25% PLODv2-filtered')\n",
        "plt.xlabel('Predicted Labels')\n",
        "plt.ylabel('True Labels')\n",
        "plt.show()\n"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
